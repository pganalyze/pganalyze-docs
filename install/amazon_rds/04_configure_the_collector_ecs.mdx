---
title: 'Step 4: Configure the Collector'
install_track_title: Installation Guide (Amazon RDS and Amazon Aurora)
backlink_href: /docs/install
backlink_title: 'Installation Guide'
---

import PublicLastStepLogInsightsLink from '../_public_last_step_log_insights_link.mdx'

export const FinishSetup = ({ inviteLink }) => {
  return (
    <div>
      In the meantime you can invite your colleagues:
      <Link className="btn btn-success" to={inviteLink}>
        Finish setup and invite team members
      </Link>
    </div>
  )
}

export const SSMConfig = ({ apiKey }) => {
  return (
    <React.Fragment>
      <CodeBlock>
        {`aws ssm put-parameter --name /pganalyze/DB_PASSWORD --type SecureString --value "YOUR_MONITORING_USER_PASSWORD"
aws ssm put-parameter --name /pganalyze/PGA_API_KEY --type SecureString --value "${
            apiKey || "YOUR_PGANALYZE_API_KEY"
          }"`}
      </CodeBlock>
      <p>
        {apiKey ? (
          <React.Fragment>
            Replace <code>YOUR_DB_PASSWORD</code> with the monitoring user
            password for your database. <code>{apiKey}</code> is your
            organization's API key.
          </React.Fragment>
        ) : (
          <React.Fragment>
            Replace <code>YOUR_PGANALYZE_API_KEY</code> with the API key from
            your organization&apos;s Settings page (under the API Keys tab),
            and <code>YOUR_DB_PASSWORD</code> with the monitoring user password
            for your database.
          </React.Fragment>
        )}
      </p>
    </React.Fragment>
  );
};

## Configuring the collector on Amazon ECS

To start, create SSM secrets for storing the pganalyze API key and database password:

<SSMConfig apiKey={props.apiKey} />

Now, save the following ECS task definition to a file, for example `pganalyze_task.json`:

```json
{
  "family": "pganalyze-fargate",
  "requiresCompatibilities": [
    "FARGATE"
  ],
  "executionRoleArn": "arn:aws:iam::YOUR_ACCOUNT_ID:role/pganalyzeTaskRole",
  "taskRoleArn": "arn:aws:iam::YOUR_ACCOUNT_ID:role/pganalyzeTaskRole",
  "networkMode": "awsvpc",
  "memory": "512",
  "cpu": "256",
  "containerDefinitions": [
    {
      "name": "pganalyze",
      "image": "quay.io/pganalyze/collector:stable",
      "essential": true,
      "environment": [
        {"name": "DB_HOST", "value": "your_database_host"},
        {"name": "DB_USERNAME", "value": "your_monitoring_user"},
        {"name": "DB_NAME", "value": "your_database_name"},
      ],
      "secrets": [
        {"name": "PGA_API_KEY", "valueFrom": "/pganalyze/PGA_API_KEY"},
        {"name": "DB_PASSWORD", "valueFrom": "/pganalyze/DB_PASSWORD"}
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/pganalyze",
          "awslogs-region": "us-east-1",
          "awslogs-stream-prefix": "pganalyze"
        }
      },
      "readonlyRootFilesystem": false,
      "mountPoints": []
    }
  ]
}
```

Make sure to modify the values for `DB_HOST`, `DB_USERNAME`, `DB_NAME`, `AWS_REGION`, `AWS_INSTANCE_ID` to be correct for your RDS instance or Aurora cluster. Also adjust `YOUR_ACCOUNT_ID` to be your AWS account ID (in the `executionRoleArn` field).

## Handling Amazon Aurora clusters vs instances

In the case of Amazon Aurora, the collector automatically resolves `cluster` endpoints to the underlying writer instance.

```json
{"name": "DB_HOST", "value": "mydbcluster.cluster-123456789012.us-east-1.rds.amazonaws.com"},
```

This will only monitor the writer instance. If you also want to monitor a reader instance, you'll need to run another Docker container,
then use the following as the environment variables:

```json
{"name": "DB_HOST", "value": "mydbcluster.cluster-ro-123456789012.us-east-1.rds.amazonaws.com"},
```

If you have multiple readers you want to monitor, you need to specify each instance endpoint separately, running one pganalyze collector Docker container for each instance:

```json
{"name": "DB_HOST", "value": "mydbinstance1.123456789012.us-east-1.rds.amazonaws.com"},
```

## Registering the task and launching it

We can now register the task definition like this, as well as create the log group:

```
aws ecs register-task-definition --cli-input-json file://pganalyze_task.json
aws logs create-log-group --log-group-name /ecs/pganalyze
```

And then launch the task like this:

```
aws ecs run-task --task-definition pganalyze-fargate --launch-type FARGATE --platform-version 1.3.0 --cluster test-cluster --network-configuration "awsvpcConfiguration={assignPublicIp=ENABLED,subnets=[subnet-YOUR_SUBNET],securityGroups=[sg-YOUR_SECURITYGROUP]}"
```

You will need to make sure that `subnet-YOUR_SUBNET` and `sg-YOUR_SECURITYGROUP` are correctly specified.

To verify that the task is running successfully, first retrieve the task ID:

```
$ aws ecs list-tasks --cluster test-cluster
{
    "taskArns": [
        "arn:aws:ecs:us-east-1:ACCOUNTID:task/TASKID"
    ]
}
```

Now you can request the logs, which should look like this:

```
$ aws logs get-log-events --log-group-name /ecs/pganalyze --log-stream-name pganalyze/pganalyze/TASKID
{
    "nextForwardToken": "...",
    "events": [
        {
            "ingestionTime": 1564856657429,
            "timestamp": 1564856653493,
            "message": "I [default] Submitted compact snapshots successfully: 5 activity, 2 logs"
        },
```

The `Submitted compact snapshots successfully` message indicates that you have
configured the collector correctly.

**Your setup is complete. The dashboard will start showing data within 15 minutes.**

<InAppOnly>
  <FinishSetup inviteLink={props.inviteLink} />
</InAppOnly>

<PublicLastStepLogInsightsLink />
