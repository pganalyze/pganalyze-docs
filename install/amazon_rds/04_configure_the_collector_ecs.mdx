---
title: 'Step 4: Configure the Collector'
install_track_title: Installation Guide (Amazon RDS and Amazon Aurora)
backlink_href: /docs/install
backlink_title: 'Installation Guide'
---

import PublicLastStepLogInsightsLink from '../_public_last_step_log_insights_link.mdx'
import { SettingEnvVarsECS } from './_04_setting_env_vars.mdx';

export const FinishSetup = ({ inviteLink }) => {
  return (
    <div>
      In the meantime you can invite your colleagues:
      <Link className="btn btn-success" to={inviteLink}>
        Finish setup and invite team members
      </Link>
    </div>
  )
}

## Configuring the collector on Amazon ECS

<SettingEnvVarsECS apiKey={props.apiKey} />

## Handling Amazon Aurora clusters vs instances

In the case of Amazon Aurora, the collector automatically resolves `cluster` endpoints to the underlying writer instance.

```json
{"name": "DB_HOST", "value": "mydbcluster.cluster-123456789012.us-east-1.rds.amazonaws.com"},
```

This will only monitor the writer instance. If you also want to monitor a reader instance,
you'll need to use the Multiple Instances method above and specify the reader instance as a
second instance within the `pganalyze_collector.conf` file, then update the `/pganalyze/CONFIG_CONTENTS`
SSM secret.

```
[pganalyze]
api_key = 'your_pga_organization_api_key'

[writer_instance]
db_host = mydbcluster.cluster-123456789012.us-east-1.rds.amazonaws.com
...

[reader_instance]
db_host = mydbcluster.cluster-ro-123456789012.us-east-1.rds.amazonaws.com
...
```

Alternatively, you can run a separate Docker container to monitor a reader instance.
Use the `cluster-ro` endpoint as the `DB_HOST` of the environment variables:

```json
{"name": "DB_HOST", "value": "mydbcluster.cluster-ro-123456789012.us-east-1.rds.amazonaws.com"},
```

If you have a cluster with multiple readers, you either need to add each instance
endpoint to the content of the `pganalyze_collector.conf` file (e.g. add each section like `[reader_instance1]`, `[reader_instance2]`),
then update the `/pganalyze/CONFIG_CONTENTS` SSM secret, or run one pganalyze
collector Docker container for each instance.

## Registering the task and launching it

We can now register the task definition like this, as well as create the log group:

```
aws ecs register-task-definition --cli-input-json file://pganalyze_task.json
aws logs create-log-group --log-group-name /ecs/pganalyze
```

And then launch the task like this:

```
aws ecs run-task --task-definition pganalyze-fargate --launch-type FARGATE --platform-version 1.3.0 --cluster test-cluster --network-configuration "awsvpcConfiguration={assignPublicIp=ENABLED,subnets=[subnet-YOUR_SUBNET],securityGroups=[sg-YOUR_SECURITYGROUP]}"
```

You will need to make sure that `subnet-YOUR_SUBNET` and `sg-YOUR_SECURITYGROUP` are correctly specified.

To verify that the task is running successfully, first retrieve the task ID:

```
$ aws ecs list-tasks --cluster test-cluster
{
    "taskArns": [
        "arn:aws:ecs:us-east-1:ACCOUNTID:task/TASKID"
    ]
}
```

Now you can request the logs, which should look like this:

```
$ aws logs get-log-events --log-group-name /ecs/pganalyze --log-stream-name pganalyze/pganalyze/TASKID
{
    "nextForwardToken": "...",
    "events": [
        {
            "ingestionTime": 1564856657429,
            "timestamp": 1564856653493,
            "message": "I [default] Submitted compact snapshots successfully: 5 activity, 2 logs"
        },
```

The `Submitted compact snapshots successfully` message indicates that you have
configured the collector correctly.

**Your setup is complete. The dashboard will start showing data within 15 minutes.**

<InAppOnly>
  <FinishSetup inviteLink={props.inviteLink} />
</InAppOnly>

<PublicLastStepLogInsightsLink />
